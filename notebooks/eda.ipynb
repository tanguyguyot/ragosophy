{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f49a03ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U -q chromadb PyMuPDF pandas sentence-transformers gradio openai prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4b179966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymupdf\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "from chromadb import Settings\n",
    "import numpy as np\n",
    "import re\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0673b95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    - str: Extracted text from the PDF.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with pymupdf.open(pdf_path) as doc:\n",
    "            text = \"\"\n",
    "            print(f\"Extracting text from: {pdf_path}\")\n",
    "            for page in doc:\n",
    "                current_text = page.get_text()\n",
    "                current_text = re.sub(r'\\xa0', ' ', current_text)  # Replace non-breaking spaces\n",
    "                text += current_text\n",
    "            title = os.path.basename(pdf_path).replace('.pdf', '')\n",
    "            print(f\"Title: {title}\")\n",
    "        return text, title\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {pdf_path}: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def get_text(df, livre, paragraph):\n",
    "    \"\"\"\n",
    "    Retrieves the text for a specific livre and paragraph.\n",
    "\n",
    "    Parameters:\n",
    "    - livre (int): The livre number.\n",
    "    - paragraph (int): The paragraph number.\n",
    "\n",
    "    Returns:\n",
    "    - str: The text of the specified livre and paragraph.\n",
    "    \"\"\"\n",
    "    return df.loc[(df.livre == livre) & (df.paragraph == paragraph)].text.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8a32476e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from: documents/Pensees_moi_meme.pdf\n",
      "Title: Pensees_moi_meme\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir('documents')\n",
    "texts = {}\n",
    "for file in files:\n",
    "    if file.endswith('.pdf'):\n",
    "        text, title = extract_text_from_pdf(os.path.join('documents', file))\n",
    "        texts[title] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ebafc587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First cleaning : remove [number] references\n",
    "\n",
    "def remove_references(text):\n",
    "    \"\"\"\n",
    "    Removes reference patterns like [1], [23] from the text.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The input text.\n",
    "\n",
    "    Returns:\n",
    "    - str: Cleaned text without references.\n",
    "    \"\"\"\n",
    "    cleaned_text = re.sub(r'\\[\\d+\\]', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def display_text(txt, width=150):\n",
    "    wrapper = textwrap.TextWrapper(width=width)\n",
    "    print(wrapper.fill(txt))\n",
    "\n",
    "cleaned_text = remove_references(txt)\n",
    "\n",
    "# Extract avant-propos as its written by different author than Marcus Aurelius\n",
    "end_avant_propos_idx = re.search(r'LIVRE PREMIER', cleaned_text).start()\n",
    "avant_propos = cleaned_text[:end_avant_propos_idx]\n",
    "cleaned_text = cleaned_text[end_avant_propos_idx:]\n",
    "\n",
    "# Remove page numbers : on whole text, we'll start at page 11 and increment and remove the first occurence of the expected page number 11 to 382\n",
    "\n",
    "def remove_page_numbers(text, start_page=11, end_page=382):\n",
    "    for page_num in range(start_page, end_page + 1):\n",
    "        pattern = r'\\n{}\\n'.format(page_num)\n",
    "        text = re.sub(pattern, '\\n', text, count=1)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5c889140",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = remove_page_numbers(cleaned_text, 11, 382)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f1e8098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking\n",
    "\n",
    "# First split : by LIVRE\n",
    "\n",
    "livres = re.split(r'LIVRE [A-Z]+', cleaned_text)[1:]\n",
    "\n",
    "# New split : by paragraph (I, II etc...)\n",
    "def get_paragraphs(text):\n",
    "    \"\"\"\n",
    "    Splits the text into paragraphs based on Roman numeral headings.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The input text.\n",
    "\n",
    "    Returns:\n",
    "    - list: List of paragraphs.\n",
    "    \"\"\" \n",
    "    return re.split(r'\\n[A-Z]+\\n', text)[1:]\n",
    "\n",
    "def get_paragraphs_split_footers(livres):\n",
    "\n",
    "    footers = {}\n",
    "    paragraphs = {}\n",
    "    for i in range(1, len(livres) + 1):\n",
    "        current_paragraphs = get_paragraphs(livres[i-1])\n",
    "        last_paragraph = current_paragraphs[-1]\n",
    "        splits = re.split(r'\\b1. ', last_paragraph, maxsplit=1)\n",
    "        try:\n",
    "            current_paragraphs[-1] = splits[0]\n",
    "            footers[i] = splits[1]\n",
    "            paragraphs[i] = current_paragraphs\n",
    "        except IndexError:\n",
    "            print(f\"No footer found for one of the books.\")\n",
    "            print('Retry after better cleaning?')\n",
    "            return None\n",
    "    return paragraphs, footers\n",
    "\n",
    "# Create dataframe to store paragraph, with column linked to livre and paragraph number\n",
    "\n",
    "\n",
    "\n",
    "paragraphs, footers = get_paragraphs_split_footers(livres)\n",
    "    \n",
    "    # Also remove capitalization ?\n",
    "# paragraphs = {k: [para.lower() for para in v] for k, v in paragraphs.items()}\n",
    "\n",
    "# Remove \\n within paragraphs\n",
    "paragraphs = {k: [para.replace('\\n', ' ') for para in v] for k, v in paragraphs.items()}\n",
    "\n",
    "df = pd.DataFrame(columns=['livre', 'paragraph', 'text'])\n",
    "for livre_num, paras in paragraphs.items():\n",
    "    for para_num, para_text in enumerate(paras, start=1):\n",
    "        df = pd.concat([df, pd.DataFrame({'livre': [livre_num], 'paragraph': [para_num], 'text': [para_text]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "59f1fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df\n",
    "\n",
    "df.to_csv('cleaned/marcus_aurelius_paragraphs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0072b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
